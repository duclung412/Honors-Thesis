{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import math\n",
    "import zipfile\n",
    "import matplotlib\n",
    "import geopandas\n",
    "import lxml\n",
    "import copy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract household income mean for districts in 2000\n",
    "df_1 = pd.read_stata(\"sddbdist_2000.dta\")\n",
    "df_1 = df_1[[\"sddbid\", \"hhinc_median\", \"state\", \"name\", \"type\", \"stfips\", \"cofips\", \"leaid\", \"hhinc_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  del sys.path[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#to get country population 1990 - 2014\n",
    "pop_years_1 = [\"pop1991\",\"pop1992\",\"pop1993\",\"pop1994\",\"pop1995\",\"pop1996\",\"pop1997\",\"pop1998\",\"pop1999\"\n",
    "            ,\"pop2000\",\"pop2001\",\"pop2002\",\"pop2003\",\"pop2004\",\"pop2005\",\"pop2006\",\"pop2007\",\"pop2008\"\n",
    "            ,\"pop2009\"]\n",
    "\n",
    "pop_years_2 = [\"pop2010\",\"pop2011\", \"pop2012\"]\n",
    "\n",
    "df_pop = pd.read_stata(\"county_population.dta\")\n",
    "#df_pop = df_pop[[\"fips\", \"state_fips\", \"county_fips\", \"country_name\"]+pop_years]\n",
    "\n",
    "\n",
    "#pop 2010 ...\n",
    "df_pop1 = df_pop[df_pop[\"region\"].notna()][df_pop[\"county_fips\"]!=0].reset_index()\n",
    "\n",
    "#pop < 2010\n",
    "df_pop2 = df_pop[df_pop[\"pop2009\"].notna()][df_pop[\"county_fips\"]!=0].reset_index()\n",
    "\n",
    "\n",
    "#df_pop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finance \n",
    "years = [1990, 1992, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005\n",
    "        , 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013]\n",
    "\n",
    "#list of sas files \n",
    "sas_files = [\n",
    "    \"finance/1990.sas7bdat\",\"finance/1992.sas7bdat\",\"finance/1995.sas7bdat\",\"finance/1996.sas7bdat\"\n",
    "    ,\"finance/1997.sas7bdat\",\"finance/1998.sas7bdat\",\"finance/1999.sas7bdat\",\"finance/2000.sas7bdat\"\n",
    "    ,\"finance/2001.sas7bdat\",\"finance/2002.sas7bdat\",\"finance/2003.sas7bdat\",\"finance/2004.sas7bdat\"\n",
    "    ,\"finance/2005.sas7bdat\",\"finance/2006.sas7bdat\",\"finance/2007.sas7bdat\",\"finance/2008.sas7bdat\"\n",
    "    ,\"finance/2009.sas7bdat\",\"finance/2010.sas7bdat\",\"finance/2011.sas7bdat\",\"finance/2012.sas7bdat\"\n",
    "    ,\"finance/2013.sas7bdat\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To converted bytes into string columms\n",
    "def convert(df):\n",
    "    df = df\n",
    "    str_df = df.select_dtypes([np.object])\n",
    "    str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "    for col in str_df:\n",
    "        df[col] = str_df[col]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To clean school revenue and expenditure data without relying on LEAID\n",
    "def stat(file_path, stats):\n",
    "    df = pd.read_sas(file_path)\n",
    "    df = convert(df)\n",
    "    \n",
    "    #some sas files have CONUM column as district FIPs numbers, others have FIPSCO as FIPS numbers\n",
    "    if \"CONUM\" in df.columns:\n",
    "        \n",
    "        #find PPR and PPE for each district. District without FIPS are ignored by default\n",
    "        df = df.groupby([\"CONUM\", \"FIPST\"]).agg(stats)\n",
    "        df[\"PPR\"] = df[\"TOTALREV\"] / df[\"V33\"]\n",
    "        df[\"PPE\"] = df[\"TOTALEXP\"] / df[\"V33\"]\n",
    "        \n",
    "        df = df.dropna().sort_values(by=\"FIPST\").reset_index()\n",
    "        \n",
    "        #rename CONUM to FIPSCO for clarity \n",
    "        df = df.rename(columns={\"CONUM\": \"FIPSCO\"})\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            df = df.groupby([\"FIPSCO\", \"FIPST\"]).agg(stats)\n",
    "            df[\"PPR\"] = df[\"TOTALREV\"] / df[\"V33\"]\n",
    "            df[\"PPE\"] = df[\"TOTALEXP\"] / df[\"V33\"]\n",
    "        \n",
    "            df = df.dropna().sort_values(by=\"FIPST\").reset_index()\n",
    "            df[\"FIPSCO\"] = df[\"FIPST\"] + df[\"FIPSCO\"]\n",
    "\n",
    "        except:\n",
    "            return \"FIPSCO not in columns\"\n",
    "    \n",
    "    df[\"YEAR\"] = int(file_path[8:12])\n",
    "    \n",
    "    return df\n",
    "\n",
    "#To clean school revenue and expenditure data, relying on LEAID\n",
    "def stat_wo(file_path, stats):\n",
    "    df = pd.read_sas(file_path)\n",
    "    df = convert(df)\n",
    "    \n",
    "\n",
    "    df = df.groupby([\"LEAID\", \"FIPST\"]).agg(stats)\n",
    "    df[\"PPR\"] = df[\"TOTALREV\"] / df[\"V33\"]\n",
    "    df[\"PPE\"] = df[\"TOTALEXP\"] / df[\"V33\"]\n",
    "        \n",
    "    df = df.dropna().sort_values(by=\"FIPST\").reset_index()\n",
    "\n",
    "    \n",
    "    df[\"YEAR\"] = int(file_path[8:12])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont touch this\n",
    "stats = {\"V33\": \"sum\", \"TOTALREV\": \"sum\", \"TFEDREV\": \"sum\", \"TSTREV\": \"sum\", \"TLOCREV\": \"sum\", \"TOTALEXP\": \"sum\"}\n",
    "\n",
    "df1 = stat(\"finance/1990.sas7bdat\", stats)\n",
    "df2 = stat(\"finance/1992.sas7bdat\", stats)\n",
    "df3 = stat(\"finance/1995.sas7bdat\", stats)\n",
    "df4 = stat(\"finance/1996.sas7bdat\", stats)\n",
    "df5 = stat(\"finance/1997.sas7bdat\", stats)\n",
    "df6 = stat(\"finance/1998.sas7bdat\", stats)\n",
    "df7 = stat(\"finance/1999.sas7bdat\", stats)\n",
    "df8 = stat(\"finance/2000.sas7bdat\", stats)\n",
    "df9 = stat(\"finance/2001.sas7bdat\", stats)\n",
    "df10 = stat(\"finance/2002.sas7bdat\", stats)\n",
    "df11 = stat(\"finance/2003.sas7bdat\", stats)\n",
    "df12 = stat(\"finance/2004.sas7bdat\", stats)\n",
    "df13 = stat(\"finance/2005.sas7bdat\", stats)\n",
    "df14 = stat(\"finance/2006.sas7bdat\", stats)\n",
    "df15 = stat(\"finance/2007.sas7bdat\", stats)\n",
    "df16 = stat(\"finance/2008.sas7bdat\", stats)\n",
    "df17 = stat(\"finance/2009.sas7bdat\", stats)\n",
    "df18 = stat(\"finance/2010.sas7bdat\", stats)\n",
    "df19 = stat(\"finance/2011.sas7bdat\", stats)\n",
    "df20 = stat(\"finance/2012.sas7bdat\", stats)\n",
    "df21 = stat(\"finance/2013.sas7bdat\", stats)\n",
    "\n",
    "df_list = [\n",
    "    df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12,\n",
    "    df13, df14, df15, df16, df17, df18, df19, df20, df21\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = stat_wo(\"finance/1990.sas7bdat\", stats)\n",
    "d2 = stat_wo(\"finance/1992.sas7bdat\", stats)\n",
    "d3 = stat_wo(\"finance/1995.sas7bdat\", stats)\n",
    "d4 = stat_wo(\"finance/1996.sas7bdat\", stats)\n",
    "d5 = stat_wo(\"finance/1997.sas7bdat\", stats)\n",
    "d6 = stat_wo(\"finance/1998.sas7bdat\", stats)\n",
    "d7 = stat_wo(\"finance/1999.sas7bdat\", stats)\n",
    "d8 = stat_wo(\"finance/2000.sas7bdat\", stats)\n",
    "d9 = stat_wo(\"finance/2001.sas7bdat\", stats)\n",
    "d10 = stat_wo(\"finance/2002.sas7bdat\", stats)\n",
    "d11 = stat_wo(\"finance/2003.sas7bdat\", stats)\n",
    "d12 = stat_wo(\"finance/2004.sas7bdat\", stats)\n",
    "d13 = stat_wo(\"finance/2005.sas7bdat\", stats)\n",
    "d14 = stat_wo(\"finance/2006.sas7bdat\", stats)\n",
    "d15 = stat_wo(\"finance/2007.sas7bdat\", stats)\n",
    "d16 = stat_wo(\"finance/2008.sas7bdat\", stats)\n",
    "d17 = stat_wo(\"finance/2009.sas7bdat\", stats)\n",
    "d18 = stat_wo(\"finance/2010.sas7bdat\", stats)\n",
    "d19 = stat_wo(\"finance/2011.sas7bdat\", stats)\n",
    "d20 = stat_wo(\"finance/2012.sas7bdat\", stats)\n",
    "d21 = stat_wo(\"finance/2013.sas7bdat\", stats)\n",
    "\n",
    "d_list = [\n",
    "    d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11, d12,\n",
    "    d13, d14, d15, d16, d17, d18, d19, d20, d21\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main dataframe for financial numbers based on FIPST\n",
    "df_main = pd.concat(df_list)\n",
    "df_main[\"FIPST\"] = df_main[\"FIPST\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state aggregate over the years\n",
    "stats_2 = stats\n",
    "stats_2[\"PPR\"] = \"sum\"\n",
    "stats_2[\"PPE\"] = \"sum\"\n",
    "df_main = df_main.groupby([\"FIPST\", \"YEAR\"]).agg(stats_2).reset_index()\n",
    "df_main[\"PPR\"] = df_main[\"TOTALREV\"]/df_main[\"V33\"]\n",
    "df_main[\"PPE\"] = df_main[\"TOTALEXP\"]/df_main[\"V33\"]\n",
    "\n",
    "#drop DC\n",
    "df_main = df_main[df_main[\"FIPST\"]!=11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event list\n",
    "df_events = pd.read_excel(\"eventlist.xlsx\")\n",
    "df_events = df_events[:-4]\n",
    "\n",
    "states_with_events = df_events.groupby(\"fips\").sum().index.astype(int).values\n",
    "states_with_events = list(states_with_events)\n",
    "\n",
    "#read cpi\n",
    "cpi = pd.read_excel(\"CPI.xlsx\")[[\"YEAR\", \"REAL\"]]\n",
    "\n",
    "#leaid\n",
    "df_id = pd.read_csv(\"LEAID.txt\", sep=\",\", thousands=\",\", encoding=\"latin-1\")\n",
    "\n",
    "#get state fipst\n",
    "df_state = pd.read_stata(\"state_fips.dta\")\n",
    "df_state = df_state.rename(columns={\"fips\": \"FIPST\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting values for no-reform and reform states\n",
    "df_reform = df_main[df_main[\"FIPST\"].isin(states_with_events)].reset_index().drop(axis=1, columns=\"index\")\n",
    "df_wo_reform = df_main[df_main[\"FIPST\"].isin(states_with_events) == False].reset_index().drop(axis=1, columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust for inflation\n",
    "def adjust(df, cpi, var, code):\n",
    "    assert code in [\"FIPST\", \"LEAID\"]\n",
    "    \n",
    "    df_adjust1 = pd.merge(df, cpi, left_on=\"YEAR\", right_on=\"YEAR\", how=\"left\")\n",
    "    df_adjust2 = df_adjust1[var].mul(df_adjust1.REAL, axis=0)\n",
    "    if code==\"FIPST\":\n",
    "        df_adjust = df_adjust1[[code, \"YEAR\", \"V33\"]].merge(df_adjust2, how=\"outer\", left_index=True, right_index=True)\n",
    "        return df_adjust\n",
    "    df_adjust = df_adjust1[[code, \"FIPST\", \"YEAR\", \"V33\"]].merge(df_adjust2, how=\"outer\", left_index=True, right_index=True)\n",
    "    return df_adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = [\"TOTALREV\", \"TFEDREV\", \"TSTREV\", \"TLOCREV\", \"TOTALEXP\", \"PPR\", \"PPE\"]\n",
    "df_reform = adjust(df_reform, cpi, var, code=\"FIPST\")\n",
    "df_wo_reform = adjust(df_wo_reform, cpi, var, code=\"FIPST\")\n",
    "df_main = adjust(df_main, cpi, var, code=\"FIPST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To CSV\n",
    "df_reform.to_csv(\"reform.csv\")\n",
    "df_wo_reform.to_csv(\"notreform.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(7,4))\n",
    "#ax = df_reform.plot(kind=\"scatter\", y=\"PPR\", x=\"YEAR\", ax=ax)\n",
    "\n",
    "#r = LinearRegression()\n",
    "#r.fit(df_reform[[\"PPR\"]].values, df[\"YEAR\"].values.reshape(-1, 1))\n",
    "#slope = float(r.coef_)\n",
    "#intercept = float(r.intercept_)\n",
    "\n",
    "#y0 = ax.get_xlim()[0]*slope + intercept\n",
    "#y1 = ax.get_xlim()[1]*slope + intercept\n",
    "\n",
    "#plt.plot(list(ax.get_xlim()), [y0, y1], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Household income 1990\n",
    "df_inc = pd.read_stata(\"getsddb1990_2015.dta\")\n",
    "\n",
    "df_inc = df_inc[[\"disttype\", \"state\", \"dist\", \"meanincA\"]]\n",
    "list_dist = list(df_inc[\"dist\"])\n",
    "#df_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract math or reading score for 4 grade pupils at the state-level for 50 states\n",
    "def clean_score(filename, scorename):\n",
    "    assert (scorename == \"READING\") or (scorename == \"MATH\")\n",
    "    assert filename[-3:] == \"csv\"\n",
    "\n",
    "    \n",
    "    #keep only state names and scores\n",
    "    df = pd.read_csv(\"scores/\"+filename)[[\"Jurisdiction\", \"MN\"]]\n",
    "\n",
    "    #drop DoDEA, Puerto Rico, and District of Columbia, and National Public for data consistency\n",
    "    df = df[df[\"Jurisdiction\"] != \"DoDEA\"][df[\"Jurisdiction\"] != \"Puerto Rico\"][df[\"Jurisdiction\"] != \"District of Columbia\"][df[\"Jurisdiction\"] != \"National public\"]\n",
    "    \n",
    "    df.index = range(len(df[\"MN\"]))\n",
    "    df = df.sort_values(by=\"Jurisdiction\").reset_index(drop=\"True\") #sort by state names and then reset indices\n",
    "    df.columns = [\"STATES\", scorename] #rename columns to jurisdiction and Math or Reading scores\n",
    "    \n",
    "    #create year column\n",
    "    if (int(filename[4:6]) >= 0) and (int(filename[4:6]) <= 13):\n",
    "        df[\"YEAR\"] = int(\"20\"+filename[4:6])\n",
    "    else:\n",
    "        df[\"YEAR\"] = int(\"19\"+filename[4:6])\n",
    "        \n",
    "    assert df.shape[0] == 50\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_files = [\"read92.csv\", \"read94.csv\", \"read98.csv\", \"read02.csv\", \"read03.csv\",\n",
    "                 \"read05.csv\", \"read07.csv\", \"read09.csv\", \"read11.csv\", \"read13.csv\"]\n",
    "math_files = [\"math92.csv\", \"math96.csv\", \"math00.csv\", \"math03.csv\",\n",
    "              \"math05.csv\", \"math07.csv\", \"math09.csv\", \"math11.csv\", \"math13.csv\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "d = clean_score(reading_files[0], \"READING\").merge(df_state, right_on=\"name\", left_on=\"STATES\", how=\"left\")\n",
    "#combine reading and math scores\n",
    "\n",
    "#create variables for reading score dataframes\n",
    "b1 = clean_score(reading_files[0], \"READING\")\n",
    "b2 = clean_score(reading_files[1], \"READING\")\n",
    "b3 = clean_score(reading_files[2], \"READING\")\n",
    "b4 = clean_score(reading_files[3], \"READING\")\n",
    "b5 = clean_score(reading_files[4], \"READING\")\n",
    "b6 = clean_score(reading_files[5], \"READING\")\n",
    "b7 = clean_score(reading_files[6], \"READING\")\n",
    "b8 = clean_score(reading_files[7], \"READING\")\n",
    "b9 = clean_score(reading_files[8], \"READING\")\n",
    "b10 = clean_score(reading_files[9], \"READING\")\n",
    "\n",
    "#create variables for math score dataframes\n",
    "c1 = clean_score(reading_files[0], \"MATH\")\n",
    "c2 = clean_score(reading_files[1], \"MATH\")\n",
    "c3 = clean_score(reading_files[2], \"MATH\")\n",
    "c4 = clean_score(reading_files[3], \"MATH\")\n",
    "c5 = clean_score(reading_files[4], \"MATH\")\n",
    "c6 = clean_score(reading_files[5], \"MATH\")\n",
    "c7 = clean_score(reading_files[6], \"MATH\")\n",
    "c8 = clean_score(reading_files[7], \"MATH\")\n",
    "c9 = clean_score(reading_files[8], \"MATH\")\n",
    "\n",
    "b = [b1, b2, b3, b4, b5, b6, b7, b8, b9, b10]\n",
    "c = [c1, c2, c3, c4, c5, c6, c7, c8, c9]\n",
    "#concatenate math and reading dataframes:\n",
    "base_reading = pd.concat(b)\n",
    "base_math = pd.concat(c)\n",
    "\n",
    "df_reading = base_reading.merge(df_state, right_on=\"name\", left_on=\"STATES\", how=\"left\")[[\"STATES\", \"READING\", \"YEAR\", \"FIPST\"]]\n",
    "df_math = base_math.merge(df_state, right_on=\"name\", left_on=\"STATES\", how=\"left\")[[\"STATES\", \"MATH\", \"YEAR\", \"FIPST\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isnumber(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#removing nan values for reading scores\n",
    "df_reading[\"READING\"] = df_reading[df_reading.applymap(isnumber)][\"READING\"]\n",
    "df1 = df_reading.dropna().reset_index()\n",
    "df1[\"READING\"] = df1[\"READING\"].astype(int)\n",
    "df_reading_1 = df1.groupby([\"STATES\", \"YEAR\"]).mean().reset_index().drop(axis=1, columns=\"index\")\n",
    "\n",
    "df_reading_1[\"REFORM\"] = np.where((df_reading_1.FIPST.isin(states_with_events)), 1, 0)\n",
    "\n",
    "\n",
    "#removing nan values for math scores\n",
    "df_math[\"MATH\"] = df_math[df_math.applymap(isnumber)][\"MATH\"]\n",
    "df2 = df_math.dropna().reset_index()\n",
    "df2[\"MATH\"] = df2[\"MATH\"].astype(int)\n",
    "df_math_1 = df2.groupby([\"STATES\", \"YEAR\"]).mean().reset_index().drop(axis=1, columns=\"index\")\n",
    "#df_math_1[\"REFORM\"] = 1\n",
    "\n",
    "df_math_1[\"REFORM\"] = np.where((df_math_1.FIPST.isin(states_with_events)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_reform = df_math_1[df_math_1[\"FIPST\"].isin(states_with_events)]\n",
    "math_wo_reform = df_math_1[df_math_1[\"FIPST\"].isin(states_with_events)==False]\n",
    "\n",
    "reading_reform = df_reading_1[df_reading_1[\"FIPST\"].isin(states_with_events)]\n",
    "reading_wo_reform = df_reading_1[df_reading_1[\"FIPST\"].isin(states_with_events)]\n",
    "\n",
    "#math_reform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat csv files for scores\n",
    "reading_reform.to_csv(\"w_reading.csv\")\n",
    "reading_wo_reform.to_csv(\"wo_reading.csv\")\n",
    "\n",
    "math_reform.to_csv(\"w_math.csv\")\n",
    "math_wo_reform.to_csv(\"wo_math.csv\")\n",
    "\n",
    "df_math_1.to_csv(\"math.csv\")\n",
    "df_reading_1.to_csv(\"reading.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main dataframe based on LEAID\n",
    "d_main = pd.concat(d_list)\n",
    "d_main[\"FIPST\"] = d_main[\"FIPST\"].astype(int)\n",
    "d_main = d_main[(d_main[\"TOTALREV\"]>0) & (d_main[\"V33\"]>0)]\n",
    "\n",
    "#d_main = d_main[d_main[\"YEAR\"]==1990]\n",
    "\n",
    "d_main = d_main.merge(df_1, right_on=\"leaid\", left_on=\"LEAID\").drop(axis=1, columns=[\"state\", \"name\", \"type\", \"cofips\", \"stfips\", \"leaid\", \"sddbid\"])\n",
    "d_main = d_main.dropna().reset_index().drop(axis=1, columns=\"index\")\n",
    "\n",
    "var = [\"TOTALREV\", \"TFEDREV\", \"TSTREV\", \"TLOCREV\", \"TOTALEXP\", \"PPR\", \"PPE\", \"hhinc_median\", \"hhinc_mean\"]\n",
    "d_main = adjust(d_main, cpi, var, code=\"LEAID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_main_year = d_main[d_main[\"YEAR\"]==1990]\n",
    "s1 = d_main_year.groupby([\"FIPST\"])[\"hhinc_mean\"].quantile(0.05)\n",
    "s2 = d_main_year.groupby([\"FIPST\"])[\"hhinc_mean\"].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_main1 = d_main_year.merge(s1, left_on=\"FIPST\", right_on=\"FIPST\").merge(s2, left_on=\"FIPST\", right_on=\"FIPST\")\n",
    "d_main1 = d_main1.rename(columns={\"hhinc_median\": \"HHINC_MEDIAN\", \"hhinc_mean_x\": \"HHINC_MEAN\", \"hhinc_mean_y\": \"Q1\", \"hhinc_mean\": \"Q5\"})\n",
    "d_main1[\"REFORM\"] = np.where((d_main1.FIPST.isin(states_with_events)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find counties below q1 and above q5\n",
    "inc1 = d_main1[d_main1[\"HHINC_MEAN\"]<d_main1[\"Q1\"]]\n",
    "inc2 = d_main1[d_main1[\"HHINC_MEAN\"]>d_main1[\"Q5\"]]\n",
    "\n",
    "list_leaid1 = list(inc1[\"LEAID\"])\n",
    "list_leaid2 = list(inc2[\"LEAID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_income1 = copy.deepcopy(d_main[d_main[\"LEAID\"].isin(list_leaid1)])\n",
    "d_income1[\"REFORM\"] = np.where((d_income1.FIPST.isin(states_with_events)), 1, 0)\n",
    "d_income2 = copy.deepcopy(d_main[d_main[\"LEAID\"].isin(list_leaid2)])\n",
    "d_income2[\"REFORM\"] = np.where((d_income2.FIPST.isin(states_with_events)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with reforms \n",
    "\n",
    "wreform_q1 = d_income1[d_income1[\"REFORM\"]==1]\n",
    "wreform_q5 = d_income2[d_income2[\"REFORM\"]==1]\n",
    "\n",
    "mean1 = wreform_q1.groupby([\"YEAR\"]).mean().reset_index()\n",
    "mean2 = wreform_q5.groupby([\"YEAR\"]).mean().reset_index()\n",
    "\n",
    "#without reforms \n",
    "\n",
    "woreform_q1 = d_income1[d_income1[\"REFORM\"]==0]\n",
    "woreform_q5 = d_income2[d_income2[\"REFORM\"]==0]\n",
    "\n",
    "mean3 = woreform_q1.groupby([\"YEAR\"]).mean().reset_index()\n",
    "mean4 = woreform_q5.groupby([\"YEAR\"]).mean().reset_index()\n",
    "\n",
    "dif1 = (mean1-mean2)[\"PPR\"]\n",
    "dif2 = (mean3-mean4)[\"PPR\"]\n",
    "\n",
    "\n",
    "f1 = copy.deepcopy(mean1[[\"YEAR\"]])\n",
    "f1[\"DIFFERENCE\"] = dif1\n",
    "f1[\"REFORM\"] = 1\n",
    "\n",
    "f2 = copy.deepcopy(mean1[[\"YEAR\"]])\n",
    "f2[\"DIFFERENCE\"] = dif2\n",
    "f2[\"REFORM\"] = 0\n",
    "\n",
    "f3 = pd.concat([f1, f2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3.to_csv(\"difference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
